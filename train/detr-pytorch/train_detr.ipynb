{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DetrConfig, DetrForObjectDetection\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import json\n",
    "from transformers import DetrFeatureExtractor\n",
    "import torchvision\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from detr.datasets import get_coco_api_from_dataset\n",
    "from detr.datasets.coco_eval import CocoEvaluator\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\MinGW\\bin\\mingwstartup.bat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#Make dir for data\n",
    "%mkdir content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\CARLA_0.9.13\\PythonAPI\\Research-Project-CARLA\\train\\detr-pytorch\\content\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in CARLA-19 to coco: 100% [53436436 / 53436436] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to CARLA-19 in coco:: 100%|██████████| 1866/1866 [00:01<00:00, 1183.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#Download data from roboflow of download manual from kaggle\n",
    "from roboflow import Roboflow\n",
    "%cd content\n",
    "rf = Roboflow(api_key=\"ruQpTRXWHhPyIXpWAIh5\")\n",
    "project = rf.workspace().project(\"carla-izloa\")\n",
    "dataset = project.version(19).download(\"coco\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\CARLA_0.9.13\\PythonAPI\\Research-Project-CARLA\\train\\detr-pytorch\n"
     ]
    }
   ],
   "source": [
    "#Return to main dir\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, img_folder, feature_extractor, train=True):\n",
    "        ann_file = os.path.join(img_folder, \"_annotations.coco.json\")\n",
    "        super(CocoDetection, self).__init__(img_folder, ann_file)\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "        # preprocess image and target\n",
    "        image_id = self.ids[idx]\n",
    "        target = {'image_id': image_id, 'annotations': target}\n",
    "        encoding = self.feature_extractor(\n",
    "            images=img, annotations=target, return_tensors=\"pt\")\n",
    "        # remove batch dimension\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]  # remove batch dimension\n",
    "\n",
    "        return pixel_values, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETR MODEL, turned into lightning module\n",
    "class DetrLightning(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, lr, lr_backbone, weight_decay):\n",
    "        super().__init__()\n",
    "        labels = self.load_labels()\n",
    "        detr_config = DetrConfig(num_queries=20)#change num_queries, default on coco is 100, I use 20 since my data has only 10 classes.\n",
    "        self.model = DetrForObjectDetection(detr_config).from_pretrained(\"facebook/detr-resnet-50\",\n",
    "                                                            num_labels=len(\n",
    "                                                                labels),\n",
    "                                                            ignore_mismatched_sizes=True)\n",
    "        self.model.config.num_queries = 20\n",
    "        self.lr = lr\n",
    "        self.lr_backbone = lr_backbone\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def load_labels(self):\n",
    "        with open(\"../../detrCustom/labels.json\", \"r\") as outfile:\n",
    "            labels = json.load(outfile)\n",
    "        return labels\n",
    "\n",
    "    def forward(self, pixel_values, pixel_mask):\n",
    "        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "        return outputs\n",
    "\n",
    "    def calculate_loss(self, batch):\n",
    "        #Calculate loss for certain batch\n",
    "       pixel_values = batch[\"pixel_values\"]\n",
    "       pixel_mask = batch[\"pixel_mask\"]\n",
    "       labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "       outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "       loss = outputs.loss\n",
    "       loss_dict = outputs.loss_dict\n",
    "\n",
    "       return loss, loss_dict\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, loss_dict = self.calculate_loss(batch)\n",
    "        # Logging\n",
    "        self.log(\"training_loss\", loss)\n",
    "        for k,v in loss_dict.items():\n",
    "          self.log(\"train_\" + k, v.item())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, loss_dict = self.calculate_loss(batch)\n",
    "        # Logging\n",
    "        self.log(\"validation_loss\", loss)\n",
    "        for k,v in loss_dict.items():\n",
    "          self.log(\"validation_\" + k, v.item())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        param_dicts = [\n",
    "            {\"params\": [p for n, p in self.named_parameters(\n",
    "            ) if \"backbone\" not in n and p.requires_grad]},\n",
    "            {\n",
    "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "                \"lr\": self.lr_backbone,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(param_dicts, lr=self.lr,\n",
    "                                      weight_decay=self.weight_decay)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return val_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = DetrFeatureExtractor.from_pretrained(\n",
    "    \"facebook/detr-resnet-50\")\n",
    "\n",
    "train_dataset = CocoDetection(\n",
    "    img_folder='./content/CARLA-19/train', feature_extractor=feature_extractor)\n",
    "val_dataset = CocoDetection(img_folder='./content/CARLA-19/valid',\n",
    "                            feature_extractor=feature_extractor, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "cats = train_dataset.coco.cats\n",
    "labels = {k: v['name'] for k,v in cats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe to use in predictions\n",
    "with open(f\"../../detrCustom/labels.json\", \"w\") as outfile:\n",
    "    json.dump(labels, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders and batch with padded images to biggest size\n",
    "def create_batch(batch):\n",
    "    pixel_values = [item[0] for item in batch]\n",
    "    encoding = feature_extractor.pad_and_create_pixel_mask(\n",
    "        pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[1] for item in batch]\n",
    "    batch = {}\n",
    "    batch['pixel_values'] = encoding['pixel_values']\n",
    "    batch['pixel_mask'] = encoding['pixel_mask']\n",
    "    batch['labels'] = labels\n",
    "    return batch\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "   train_dataset, collate_fn=create_batch, batch_size=2, shuffle=True)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, collate_fn=create_batch, batch_size=2)\n",
    "batch = next(iter(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([14, 256]) in the model instantiated\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([14]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Create model - based on our pytorch lightning class\n",
    "model = DetrLightning(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
       "                   [--host ADDR] [--bind_all] [--port PORT]\n",
       "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
       "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
       "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
       "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
       "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
       "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
       "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
       "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
       "                   [--reload_multifile BOOL]\n",
       "                   [--reload_multifile_inactive_secs SECONDS]\n",
       "                   [--generic_data TYPE]\n",
       "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
       "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
       "                   [--whatif-data-dir PATH]\n",
       "                   {serve,dev} ...\n",
       "tensorboard: error: invalid choice: '-' (choose from 'serve', 'dev')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard - -logdir lightning_logs/\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                   | Params\n",
      "-------------------------------------------------\n",
      "0 | model | DetrForObjectDetection | 41.5 M\n",
      "-------------------------------------------------\n",
      "41.3 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "41.5 M    Total params\n",
      "166.050   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\anaconda3\\envs\\testgpu\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\anaconda3\\envs\\testgpu\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:60: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\anaconda3\\envs\\testgpu\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 930/930 [08:41<00:00,  1.78it/s, loss=1.5, v_num=1] \n"
     ]
    }
   ],
   "source": [
    "# Use pytorch lightning trainer to start training\n",
    "trainer = Trainer(gpus=1, max_epochs=1, gradient_clip_val=0.1)\n",
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/facebookresearch/detr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get groundtruths of the val dataset\n",
    "gt_val = get_coco_api_from_dataset(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init cocoevaluator - this comes from the detr github\n",
    "iou_types = ['bbox']\n",
    "coco_evaluator = CocoEvaluator(gt_val, iou_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use cpu for eval, set to 'cuda' if you want to use GPU\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec978fefe1694e3ca00cca7bb97323da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(tqdm(val_dataloader)):\n",
    "    # get the inputs\n",
    "    pixel_values = batch[\"pixel_values\"].to(device)\n",
    "    pixel_mask = batch[\"pixel_mask\"].to(device)\n",
    "    # these are in DETR format, resized + normalized\n",
    "    labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "    # forward pass\n",
    "    outputs = model.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "    orig_target_sizes = torch.stack(\n",
    "        [target[\"orig_size\"] for target in labels], dim=0)\n",
    "    # make outputs coco format to run evaluation\n",
    "    results = feature_extractor.post_process(outputs, orig_target_sizes)\n",
    "    res = {target['image_id'].item(): output for target,\n",
    "           output in zip(labels, results)}\n",
    "    coco_evaluator.update(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=0.35s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.439\n"
     ]
    }
   ],
   "source": [
    "# Summarize and show results\n",
    "coco_evaluator.synchronize_between_processes()\n",
    "coco_evaluator.accumulate()\n",
    "coco_evaluator.summarize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model can now be found in the lightning log. Check latest version and you can find the model in \"checkpoint\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move model to models folder,change X to the right numbers found in the logs folder.\n",
    "shutil.move(\n",
    "    'lightning_logs/version_1/checkpoints/epoch=0-step=797.ckpt', '../../models')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74c301f3fd2ba21c06aefb45cca0a58adb7a294118d238b6b18df8bb82ef45a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('testgpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
